{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given code\n",
    "def image_arrs(paths, im_arr):\n",
    "    for path in paths:\n",
    "        image = cv2.imread(path)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        #resize\n",
    "        size_image = image_from_array.resize((30,30))\n",
    "        image_arr = np.array(size_image.getdata(),np.uint8).reshape(size_image.size[1], size_image.size[0],3)\n",
    "        im_arr.append(image_arr.flatten())\n",
    "    return im_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given code\n",
    "#all file paths from classes 1-5\n",
    "df = pd.read_csv('Train.csv')\n",
    "\n",
    "paths1 = df[(df['ClassId'] ==1)]['Path'].values\n",
    "paths2 = df[(df['ClassId'] ==2)]['Path'].values\n",
    "paths3 = df[(df['ClassId'] ==3)]['Path'].values\n",
    "paths4 = df[(df['ClassId'] ==4)]['Path'].values\n",
    "paths5 = df[(df['ClassId'] ==5)]['Path'].values\n",
    "\n",
    "class1_arrs = []\n",
    "class1_arrs = image_arrs(paths1, class1_arrs)\n",
    "\n",
    "class2_arrs = []\n",
    "class2_arrs = image_arrs(paths2, class2_arrs)\n",
    "\n",
    "class3_arrs = []\n",
    "class3_arrs = image_arrs(paths3, class3_arrs)\n",
    "\n",
    "class4_arrs = []\n",
    "class4_arrs = image_arrs(paths4, class4_arrs)\n",
    "\n",
    "class5_arrs = []\n",
    "class5_arrs = image_arrs(paths5, class5_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n"
     ]
    }
   ],
   "source": [
    "print(len(class1_arrs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given code\n",
    "#concat data/labels\n",
    "X = class1_arrs + class2_arrs + class3_arrs + class4_arrs + class5_arrs\n",
    "y = (len(class1_arrs)*[0]) + (len(class2_arrs)*[1]) + (len(class3_arrs)*[2]) + (len(class4_arrs)*[3]) + (len(class5_arrs)*[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given code - split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given code - convert from np array to tensor\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data?\n",
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "    train_data.append([X_train[i], y_train[i]])\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append([X_test[i], y_test[i]])\n",
    "    \n",
    "trainset = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for each in trainset:\n",
    "    total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = each[0][0], each[1][0]\n",
    "\n",
    "print(y)\n",
    "#why doesn't it show the actual sign?\n",
    "plt.imshow(x.view(30,30,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Build NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2700, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (fc3): Linear(in_features=30, out_features=60, bias=True)\n",
      "  (fc4): Linear(in_features=60, out_features=60, bias=True)\n",
      "  (fc5): Linear(in_features=60, out_features=60, bias=True)\n",
      "  (fc6): Linear(in_features=60, out_features=30, bias=True)\n",
      "  (fc7): Linear(in_features=30, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    #define layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2700, 10)\n",
    "        self.fc2 = nn.Linear(10,30)\n",
    "        self.fc3 = nn.Linear(30,60)\n",
    "        self.fc4 = nn.Linear(60,60)\n",
    "        self.fc5 = nn.Linear(60,60)\n",
    "        self.fc6 = nn.Linear(60,30)\n",
    "        self.fc7 = nn.Linear(30,5)\n",
    "        \n",
    "    #passing through each layer\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6491, -1.5787, -1.4623, -1.6388, -1.7395]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "#random input to make sure it works\n",
    "randoms = torch.rand(2700)\n",
    "randoms = randoms.view(-1, 2700)\n",
    "\n",
    "output = net(randoms)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6588, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6229, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5704, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5781, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6259, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5265, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6746, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6145, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6270, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5694, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        #want gradient to be 0 each time\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,2700))\n",
    "        loss = criterion(output, y)\n",
    "        #backpropagating the loss\n",
    "        loss.backward()\n",
    "        #taking the steps to decrease loss\n",
    "        optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print(loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
